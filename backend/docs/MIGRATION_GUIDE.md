# BARQ Fleet Management - Migration Guide

## Quick Reference

This guide covers all database migration operations for the BARQ Fleet Management system.

---

## Table of Contents

1. [Prerequisites](#prerequisites)
2. [Common Commands](#common-commands)
3. [Migration Workflow](#migration-workflow)
4. [Best Practices](#best-practices)
5. [Troubleshooting](#troubleshooting)

---

## Prerequisites

### Required Tools
```bash
# PostgreSQL 14+
psql --version

# Python 3.11+
python --version

# Alembic (installed via requirements.txt)
alembic --version
```

### Environment Setup
```bash
# Create .env file
cp .env.example .env

# Set database URL
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/barq_fleet

# Activate virtual environment
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows
```

---

## Common Commands

### Check Current State

```bash
# Show current migration version
alembic current

# Show migration history
alembic history

# Show detailed history with SQL
alembic history --verbose

# Show pending migrations
alembic current -v
```

### Create Migrations

```bash
# Auto-generate migration from model changes
alembic revision --autogenerate -m "add new analytics models"

# Create empty migration (manual)
alembic revision -m "add custom indexes"

# Create migration with specific message format
alembic revision --autogenerate -m "module_name: description"

# Examples:
alembic revision --autogenerate -m "fleet: add vehicle telematics"
alembic revision --autogenerate -m "hr: update salary structure"
```

### Apply Migrations

```bash
# Upgrade to latest version
alembic upgrade head

# Upgrade one version
alembic upgrade +1

# Upgrade to specific version
alembic upgrade ae1027a6acf

# Dry run (show SQL without executing)
alembic upgrade head --sql
```

### Rollback Migrations

```bash
# Downgrade one version
alembic downgrade -1

# Downgrade to specific version
alembic downgrade ae1027a6acf

# Downgrade to base (empty database)
alembic downgrade base

# Show SQL for downgrade
alembic downgrade -1 --sql
```

### Stamp Database

```bash
# Mark database as being at a specific version (without running migrations)
alembic stamp head

# Stamp to specific version
alembic stamp ae1027a6acf

# Useful when:
# - Importing from backup
# - Manual schema changes
# - Syncing development database
```

---

## Migration Workflow

### Development Workflow

```bash
# 1. Make model changes
# Edit files in app/models/

# 2. Generate migration
alembic revision --autogenerate -m "describe your changes"

# 3. Review generated migration
cat alembic/versions/YYYYMMDD_HHMM_xxxx_describe_your_changes.py

# 4. Edit if needed (add data migrations, custom SQL, etc.)
nano alembic/versions/YYYYMMDD_HHMM_xxxx_describe_your_changes.py

# 5. Test migration
alembic upgrade head

# 6. Test rollback
alembic downgrade -1

# 7. Test forward again
alembic upgrade head

# 8. Commit migration file
git add alembic/versions/YYYYMMDD_HHMM_xxxx_describe_your_changes.py
git commit -m "Add migration: describe your changes"
```

### Production Deployment

```bash
# 1. BACKUP FIRST!
pg_dump -h $DB_HOST -U $DB_USER -Fc $DB_NAME > backup_$(date +%Y%m%d_%H%M%S).dump

# 2. Check current version
alembic current

# 3. Show pending migrations
alembic history

# 4. Dry run (review SQL)
alembic upgrade head --sql | less

# 5. Apply migrations
alembic upgrade head

# 6. Verify
alembic current
psql -h $DB_HOST -U $DB_USER -d $DB_NAME -c "\dt"

# 7. If issues, rollback
alembic downgrade -1
# OR restore from backup
pg_restore -h $DB_HOST -U $DB_USER -d $DB_NAME backup.dump
```

---

## Migration File Structure

### Auto-generated Migration Example

```python
"""add advanced analytics models

Revision ID: dbfbd2a3e4e4
Revises: 3e1f8b9c7d6a
Create Date: 2025-12-02 06:50:00.000000

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers
revision = 'dbfbd2a3e4e4'
down_revision = '3e1f8b9c7d6a'
branch_labels = None
depends_on = None

def upgrade() -> None:
    # ### commands auto generated by Alembic ###
    op.create_table('metric_snapshots',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('metric_name', sa.String(length=100), nullable=False),
        sa.Column('metric_type', sa.String(length=50), nullable=False),
        sa.Column('value', sa.Numeric(precision=20, scale=4), nullable=False),
        sa.Column('dimensions', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
        sa.Column('timestamp', sa.DateTime(timezone=True), nullable=False),
        sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
        sa.Column('updated_at', sa.DateTime(timezone=True), nullable=True),
        sa.PrimaryKeyConstraint('id')
    )
    op.create_index('idx_metric_name_timestamp', 'metric_snapshots', ['metric_name', 'timestamp'])
    op.create_index('idx_dimensions_gin', 'metric_snapshots', ['dimensions'], postgresql_using='gin')
    # ### end Alembic commands ###

def downgrade() -> None:
    # ### commands auto generated by Alembic ###
    op.drop_index('idx_dimensions_gin', table_name='metric_snapshots')
    op.drop_index('idx_metric_name_timestamp', table_name='metric_snapshots')
    op.drop_table('metric_snapshots')
    # ### end Alembic commands ###
```

### Manual Migration Example

```python
"""add custom performance indexes

Revision ID: 1a2b3c4d5e6f
Revises: dbfbd2a3e4e4
Create Date: 2025-12-02 10:00:00.000000

"""
from alembic import op
import sqlalchemy as sa

revision = '1a2b3c4d5e6f'
down_revision = 'dbfbd2a3e4e4'
branch_labels = None
depends_on = None

def upgrade() -> None:
    # Add composite index for common query pattern
    op.create_index(
        'idx_deliveries_courier_status_date',
        'deliveries',
        ['courier_id', 'status', 'pickup_time'],
        unique=False
    )

    # Add partial index for active deliveries only
    op.create_index(
        'idx_deliveries_active',
        'deliveries',
        ['courier_id', 'pickup_time'],
        unique=False,
        postgresql_where=sa.text("status IN ('PENDING', 'IN_TRANSIT')")
    )

    # Add GIN index for full-text search
    op.execute("""
        CREATE INDEX idx_couriers_fulltext ON couriers
        USING GIN (to_tsvector('english', full_name || ' ' || email || ' ' || mobile_number))
    """)

def downgrade() -> None:
    op.drop_index('idx_deliveries_courier_status_date', table_name='deliveries')
    op.drop_index('idx_deliveries_active', table_name='deliveries')
    op.execute("DROP INDEX idx_couriers_fulltext")
```

### Data Migration Example

```python
"""migrate legacy courier data

Revision ID: 2b3c4d5e6f7g
Revises: 1a2b3c4d5e6f
Create Date: 2025-12-03 10:00:00.000000

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.sql import table, column

revision = '2b3c4d5e6f7g'
down_revision = '1a2b3c4d5e6f'
branch_labels = None
depends_on = None

def upgrade() -> None:
    # Add new column
    op.add_column('couriers', sa.Column('legacy_id', sa.String(50), nullable=True))

    # Migrate data from old format
    couriers = table('couriers',
        column('id', sa.Integer),
        column('barq_id', sa.String),
        column('legacy_id', sa.String)
    )

    # Update legacy_id from barq_id
    op.execute(
        couriers.update().values(
            legacy_id=sa.func.substr(couriers.c.barq_id, 1, 10)
        )
    )

    # Add index
    op.create_index('idx_couriers_legacy_id', 'couriers', ['legacy_id'])

def downgrade() -> None:
    op.drop_index('idx_couriers_legacy_id', table_name='couriers')
    op.drop_column('couriers', 'legacy_id')
```

---

## Best Practices

### Before Creating Migration

1. **Review Model Changes**
   ```bash
   git diff app/models/
   ```

2. **Check for Breaking Changes**
   - Column renames → Need data migration
   - Column deletions → Backup data first
   - Foreign key changes → Check dependencies

3. **Plan Rollback Strategy**
   - Can you safely rollback?
   - Do you need to preserve data?
   - Are there dependencies?

### Creating Migration

1. **Use Descriptive Names**
   ```bash
   # Good
   alembic revision --autogenerate -m "fleet: add vehicle telematics tracking"
   alembic revision --autogenerate -m "hr: update leave balance calculation"

   # Bad
   alembic revision --autogenerate -m "update"
   alembic revision --autogenerate -m "fix stuff"
   ```

2. **Review Generated SQL**
   - Check all CREATE/ALTER statements
   - Verify indexes are created
   - Check foreign key constraints
   - Look for potential issues (NULL constraints on existing data)

3. **Test Thoroughly**
   ```bash
   # Test upgrade
   alembic upgrade head

   # Test rollback
   alembic downgrade -1

   # Test upgrade again
   alembic upgrade head
   ```

### Applying Migration

1. **Development**
   - Apply immediately
   - Test with realistic data
   - Check application still works

2. **Staging**
   - Apply during maintenance window
   - Restore from production backup first
   - Run full test suite
   - Monitor performance

3. **Production**
   - **ALWAYS BACKUP FIRST**
   - Schedule maintenance window
   - Notify users
   - Have rollback plan ready
   - Monitor closely after deployment

---

## Advanced Techniques

### Branching Migrations

```bash
# Create branch
alembic revision --autogenerate -m "feature A" --branch-label feature_a

# Merge branches
alembic merge heads -m "merge feature branches"
```

### Custom SQL Migrations

```python
def upgrade() -> None:
    # Execute raw SQL
    op.execute("""
        CREATE OR REPLACE FUNCTION update_modified_column()
        RETURNS TRIGGER AS $$
        BEGIN
            NEW.updated_at = now();
            RETURN NEW;
        END;
        $$ language 'plpgsql';
    """)

    op.execute("""
        CREATE TRIGGER update_courier_modtime
        BEFORE UPDATE ON couriers
        FOR EACH ROW
        EXECUTE FUNCTION update_modified_column();
    """)

def downgrade() -> None:
    op.execute("DROP TRIGGER update_courier_modtime ON couriers")
    op.execute("DROP FUNCTION update_modified_column()")
```

### Batch Operations (for large tables)

```python
def upgrade() -> None:
    # For large tables, use batch mode to avoid locks
    with op.batch_alter_table('deliveries') as batch_op:
        batch_op.add_column(sa.Column('new_field', sa.String(100)))
        batch_op.create_index('idx_deliveries_new_field', ['new_field'])
```

### Concurrent Index Creation

```python
def upgrade() -> None:
    # Create index concurrently (no table lock)
    op.create_index(
        'idx_deliveries_status',
        'deliveries',
        ['status'],
        postgresql_concurrently=True
    )

# Note: Must be outside transaction
# Add to migration:
# operations = [...]
# with op.get_context().autocommit_block():
#     op.execute("CREATE INDEX CONCURRENTLY ...")
```

---

## Troubleshooting

### Common Issues

#### 1. "Target database is not up to date"

```bash
# Check current version
alembic current

# Check if behind
alembic history

# Upgrade to latest
alembic upgrade head
```

#### 2. "Multiple heads detected"

```bash
# Show heads
alembic heads

# Merge heads
alembic merge heads -m "merge migrations"
```

#### 3. "Migration fails midway"

```bash
# Check error message
alembic upgrade head

# Rollback to last working version
alembic downgrade <previous_version>

# Fix migration file
nano alembic/versions/<migration_file>.py

# Try again
alembic upgrade head
```

#### 4. "Database schema out of sync"

```bash
# Option 1: Stamp to current state (if schema manually updated)
alembic stamp head

# Option 2: Drop and recreate (development only!)
alembic downgrade base
alembic upgrade head

# Option 3: Fix manually and stamp
psql -d barq_fleet -f manual_fixes.sql
alembic stamp head
```

#### 5. "Cannot add NOT NULL column to existing table"

```python
# Wrong
op.add_column('couriers', sa.Column('new_field', sa.String(), nullable=False))

# Right - add as nullable first, then update
def upgrade() -> None:
    # Add as nullable
    op.add_column('couriers', sa.Column('new_field', sa.String(), nullable=True))

    # Set default value for existing rows
    op.execute("UPDATE couriers SET new_field = 'default_value' WHERE new_field IS NULL")

    # Make NOT NULL
    op.alter_column('couriers', 'new_field', nullable=False)
```

### Debug Mode

```bash
# Show SQL without executing
alembic upgrade head --sql

# Verbose output
alembic -v upgrade head

# Show Python context
alembic current -v
```

### Manual Database Inspection

```bash
# Connect to database
psql -h localhost -U postgres -d barq_fleet

# Show tables
\dt

# Show table structure
\d couriers

# Show indexes
\di

# Show foreign keys
SELECT
    tc.table_name,
    kcu.column_name,
    ccu.table_name AS foreign_table_name,
    ccu.column_name AS foreign_column_name
FROM information_schema.table_constraints AS tc
JOIN information_schema.key_column_usage AS kcu
  ON tc.constraint_name = kcu.constraint_name
JOIN information_schema.constraint_column_usage AS ccu
  ON ccu.constraint_name = tc.constraint_name
WHERE tc.constraint_type = 'FOREIGN KEY';

# Check migration version
SELECT * FROM alembic_version;
```

---

## Migration Checklist

### Pre-Migration

- [ ] Backup database
- [ ] Review migration files
- [ ] Test on development database
- [ ] Test on staging with production data copy
- [ ] Check for breaking changes
- [ ] Plan rollback strategy
- [ ] Schedule maintenance window (production)
- [ ] Notify users (production)

### During Migration

- [ ] Set maintenance mode (if needed)
- [ ] Run migration
- [ ] Verify success
- [ ] Check application functionality
- [ ] Monitor database performance
- [ ] Check logs for errors

### Post-Migration

- [ ] Verify data integrity
- [ ] Run test suite
- [ ] Monitor application performance
- [ ] Clear maintenance mode
- [ ] Document any issues
- [ ] Keep backup for 7 days

---

## Emergency Rollback Procedure

```bash
# 1. Immediately stop application
systemctl stop barq-backend

# 2. Check current version
alembic current

# 3. Quick rollback (if recent migration)
alembic downgrade -1

# 4. If rollback fails, restore from backup
pg_restore -h localhost -U postgres -d barq_fleet backup.dump

# 5. Stamp database to backup version
alembic stamp <backup_version>

# 6. Start application
systemctl start barq-backend

# 7. Investigate issue
tail -f /var/log/barq/backend.log
```

---

## Helpful Aliases

Add to your `.bashrc` or `.zshrc`:

```bash
# Alembic aliases
alias amr='alembic revision --autogenerate -m'  # Create migration
alias amu='alembic upgrade head'                # Upgrade
alias amd='alembic downgrade -1'                # Downgrade
alias amc='alembic current'                     # Current version
alias amh='alembic history'                     # History
alias ams='alembic upgrade head --sql'          # Show SQL

# Combined workflows
alias am-test='alembic upgrade head && alembic downgrade -1 && alembic upgrade head'
alias am-check='alembic current -v && alembic history'
```

---

## Resources

### Documentation
- [Alembic Documentation](https://alembic.sqlalchemy.org/)
- [SQLAlchemy Documentation](https://docs.sqlalchemy.org/)
- [PostgreSQL Documentation](https://www.postgresql.org/docs/)

### Internal Documentation
- [Database Schema](./DATABASE_SCHEMA.md)
- [Model Summary](./MODEL_SUMMARY.md)
- [API Documentation](../README.md)

---

**Last Updated**: December 2, 2025
**Version**: v1.0
**Maintained By**: Database Architecture Team
